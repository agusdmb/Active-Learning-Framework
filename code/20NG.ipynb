{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Learner sobre 20 News Groups\n",
    "\n",
    "## Imports\n",
    "\n",
    "### Del proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import TransformerMixin\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Del framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core import ActiveLearner, Dataset, Oracle\n",
    "from querys import CertaintySelector, UncertaintySelector, RandomSelector, MinDiffSelector, EntropySelector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones y constantes para el preproceso de los datos y partición del mismo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_each_category(dataset, n):\n",
    "    train = []\n",
    "    for cat in range(len(dataset.target_names)):\n",
    "        count = 0\n",
    "        i = 0\n",
    "        while count < n and i < len(dataset.target):\n",
    "            if dataset.target[i] == cat:\n",
    "                train.append(i)\n",
    "                count += 1\n",
    "            i += 1\n",
    "    train.sort()\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_from_dataset(dataset, i):\n",
    "    del dataset.data[i]\n",
    "    dataset.target = np.delete(dataset.target, i)\n",
    "    dataset.filenames = np.delete(dataset.filenames, i)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_many_from_dataset(dataset, indices):\n",
    "    for i, index in enumerate(indices):\n",
    "        dataset = remove_from_dataset(dataset, index-i)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_data(dataset, train_indices):\n",
    "    train_data = []\n",
    "    train_target = []\n",
    "    for i in train_indices:\n",
    "        train_data.append(dataset.data[i])\n",
    "        train_target.append(dataset.target[i])\n",
    "    dataset = remove_many_from_dataset(dataset, train_indices)\n",
    "    return dataset, train_data, train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(dataset):\n",
    "    chars = set(\"abcdefghijklmnopqrstuvwxyz\")\n",
    "    to_remove = []\n",
    "    for i in range(len(dataset.data)):\n",
    "        dataset.data[i] = dataset.data[i].strip()\n",
    "        dataset.data[i] = dataset.data[i].lower()\n",
    "        if len(dataset.data[i]) == 0:\n",
    "            to_remove.append(i)\n",
    "        elif not any((c in chars) for c in dataset.data[i]):\n",
    "            to_remove.append(i)\n",
    "        else:\n",
    "            txt = dataset.data[i].split(' ')\n",
    "            if len(txt) < 100:\n",
    "                to_remove.append(i)\n",
    "        \n",
    "    \n",
    "    return remove_many_from_dataset(dataset, to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    'alt.atheism',\n",
    "    'comp.graphics',\n",
    "#    'comp.os.ms-windows.misc',\n",
    "#    'comp.sys.ibm.pc.hardware',\n",
    "#    'comp.sys.mac.hardware',\n",
    "#    'comp.windows.x',\n",
    "    'misc.forsale',\n",
    "#    'rec.autos',\n",
    "    'rec.motorcycles',\n",
    "#    'rec.sport.baseball',\n",
    "#    'rec.sport.hockey',\n",
    "#    'sci.crypt',\n",
    "#    'sci.electronics',\n",
    "    'sci.med',\n",
    "#    'sci.space',\n",
    "#    'soc.religion.christian',\n",
    "    'talk.politics.guns',\n",
    "#    'talk.politics.mideast',\n",
    "#    'talk.politics.misc',\n",
    "#    'talk.religion.misc',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtengo los datos\n",
    "\n",
    "Solo las categorias definidas anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), categories=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpio los artículos que no posean información relevante, por ejemplo, hay más de uno que esta vacío."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = clean_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecciono 10 instancias de cada clase para iniciar el Active Lerning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = get_n_each_category(dataset, 10)\n",
    "dataset, train_data, train_target = split_train_data(dataset, train_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datos para el testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), categories=categories)\n",
    "#test_dataset = clean_dataset(test_dataset)\n",
    "test_data = test_dataset.data\n",
    "test_target = test_dataset.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtengo los features TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_data)\n",
    "X_unlabeled = vectorizer.transform(dataset.data)\n",
    "X_test = vectorizer.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(train_data).reshape(len(train_data), 1)\n",
    "X_unlabeled = np.array(dataset.data).reshape(len(dataset.data), 1)\n",
    "X_test = np.array(test_data).reshape(len(test_data), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instancio lo mínimo necesario para el framework\n",
    "\n",
    "Esto es, el **Dataset** y el **Oracle**. Además al Oracle lo modifico para que en lugar de pedir las etiquetas al usuario etiquetador, las devuelva el mismo. Esto lo hago para acelerar el proceso de evaluación del Framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGDataset(Dataset):\n",
    "    dataset = dataset\n",
    "    \n",
    "    def get_unlabeled_readable(self, i):\n",
    "        #return self.dataset.data[i]\n",
    "        return self.dataset.target[i]\n",
    "\n",
    "\n",
    "class NewsGroupOracle(Oracle):\n",
    "    target_names = dataset.target_names\n",
    "    \n",
    "    def ask(self, X_readable, recoms):\n",
    "        return X_readable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación Final\n",
    "\n",
    "Comparación de los selectores de Active Learning y también del selector RandomSelector (el cual es equivalente a no aplicar Active Learning. Se compara una vez a cada uno de los selectores del framework excepto el RandomSelector, que es el unico que tiene un comportamiento no determinístico. Por esta razón se ejecutan 5 instancias del mismo y luego se calcula un promedio de ellos para ver el desepempeño medio del mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleExtractor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, x, y=None):\n",
    "        return [ elem[0] for elem in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectors = [CertaintySelector, UncertaintySelector, MinDiffSelector, EntropySelector, RandomSelector, RandomSelector, RandomSelector, RandomSelector, RandomSelector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_scores = []\n",
    "a = time.time()\n",
    "for selector in selectors:\n",
    "    y_train = np.array(train_target)\n",
    "    ngdataset = NGDataset(X_train, y_train, X_unlabeled)\n",
    "\n",
    "    model = Pipeline([\n",
    "        ('extractor', SampleExtractor()),\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('model', MultinomialNB(alpha=0.1))\n",
    "    ])\n",
    "    oracle = NewsGroupOracle()\n",
    "    al = ActiveLearner(model, ngdataset, selector, oracle)\n",
    "    scores = []\n",
    "\n",
    "    al.fit()\n",
    "    scores.append(al.model.score(X_test, test_target))\n",
    "\n",
    "    for _ in tqdm(range(300)):\n",
    "        selected = al.select(10)\n",
    "        y = al.ask(selected)\n",
    "        al.tag_elements(selected, y)\n",
    "        al.fit()\n",
    "        scores.append(al.model.score(X_test, test_target))\n",
    "    \n",
    "    selector_scores.append(scores)\n",
    "b = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b - a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_avg = []\n",
    "for i in range(len(selector_scores[0])):\n",
    "    suma = 0\n",
    "    for selector in selector_scores[4:]:\n",
    "        suma += selector[i]\n",
    "    random_avg.append(suma/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 20}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "plt.title('Comparación de selectores')\n",
    "plt.xlabel('Iteraciones')\n",
    "plt.ylabel('Precision')\n",
    "plt.plot(selector_scores[0][:500])\n",
    "plt.plot(selector_scores[1][:500])\n",
    "plt.plot(selector_scores[2][:500])\n",
    "plt.plot(selector_scores[3][:500])\n",
    "plt.plot(selector_scores[4][:500], color='silver')\n",
    "plt.plot(selector_scores[5][:500], color='silver')\n",
    "plt.plot(selector_scores[6][:500], color='silver')\n",
    "plt.plot(selector_scores[7][:500], color='silver')\n",
    "plt.plot(selector_scores[8][:500], color='silver')\n",
    "#plt.plot(random_avg[:500], color='black')\n",
    "plt.legend(['Certainty', 'Uncertainty', 'MinDiff', 'Entropy', 'Random'])\n",
    "plt.savefig('clean_4categories')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis",
   "language": "python",
   "name": "tesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
