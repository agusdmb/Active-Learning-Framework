{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Learner sobre 20 News Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtengo el dataset desde sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core import ActiveLearner, Dataset, Oracle\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from querys import CertaintySelector, UncertaintySelector, RandomSelector, MinDiffSelector, EntropySelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_each_category(dataset, n):\n",
    "    train = []\n",
    "    for cat in range(len(dataset.target_names)):\n",
    "        count = 0\n",
    "        i = 0\n",
    "        while count < n and i < len(dataset.target):\n",
    "            if dataset.target[i] == cat:\n",
    "                train.append(i)\n",
    "                count += 1\n",
    "            i += 1\n",
    "    train.sort()\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_from_dataset(dataset, i):\n",
    "    del dataset.data[i]\n",
    "    dataset.target = np.delete(dataset.target, i)\n",
    "    dataset.filenames = np.delete(dataset.filenames, i)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_many_from_dataset(dataset, indices):\n",
    "    for i, index in enumerate(indices):\n",
    "        dataset = remove_from_dataset(dataset, index-i)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_data(dataset, train_indices):\n",
    "    train_data = []\n",
    "    train_target = []\n",
    "    for i in train_indices:\n",
    "        train_data.append(dataset.data[i])\n",
    "        train_target.append(dataset.target[i])\n",
    "    dataset = remove_many_from_dataset(dataset, train_indices)\n",
    "    return dataset, train_data, train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(dataset):\n",
    "    chars = set(\"abcdefghijklmnopqrstuvwxyz\")\n",
    "    to_remove = []\n",
    "    for i in range(len(dataset.data)):\n",
    "        dataset.data[i] = dataset.data[i].strip()\n",
    "        dataset.data[i] = dataset.data[i].lower()\n",
    "        if len(dataset.data[i]) == 0:\n",
    "            to_remove.append(i)\n",
    "        if not any((c in chars) for c in dataset.data[i]):\n",
    "            to_remove.append(i)\n",
    "    \n",
    "    return remove_many_from_dataset(dataset, to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "#    'alt.atheism',\n",
    "#    'comp.graphics',\n",
    "#    'comp.os.ms-windows.misc',\n",
    "#    'comp.sys.ibm.pc.hardware',\n",
    "    'comp.sys.mac.hardware',\n",
    "#    'comp.windows.x',\n",
    "    'misc.forsale',\n",
    "#    'rec.autos',\n",
    "#    'rec.motorcycles',\n",
    "#    'rec.sport.baseball',\n",
    "    'rec.sport.hockey',\n",
    "#    'sci.crypt',\n",
    "#    'sci.electronics',\n",
    "    'sci.med',\n",
    "#    'sci.space',\n",
    "    'soc.religion.christian',\n",
    "#    'talk.politics.guns',\n",
    "    'talk.politics.mideast',\n",
    "#    'talk.politics.misc',\n",
    "#    'talk.religion.misc',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'), categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = clean_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = get_n_each_category(dataset, 10)\n",
    "dataset, train_data, train_target = split_train_data(dataset, train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = get_n_each_category(dataset, 100)\n",
    "dataset, test_data, test_target = split_train_data(dataset, test_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtengo los features TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_train = vectorizer.fit_transform(train_data)\n",
    "X_unlabeled = vectorizer.transform(dataset.data)\n",
    "X_test = vectorizer.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instancio lo minimo necesario para el framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGDataset(Dataset):\n",
    "    dataset = dataset\n",
    "    \n",
    "    def get_unlabeled_readable(self, i):\n",
    "        #return self.dataset.data[i]\n",
    "        return self.dataset.target[i]\n",
    "\n",
    "y_train = np.array(train_target)\n",
    "ngdataset = NGDataset(X_train, y_train, X_unlabeled)\n",
    "\n",
    "    \n",
    "class NewsGroupOracle(Oracle):\n",
    "    target_names = dataset.target_names\n",
    "    \n",
    "    def ask(self, X_readable, recoms):\n",
    "        return X_readable\n",
    "\n",
    "\n",
    "model = MultinomialNB(alpha=.01)\n",
    "oracle = NewsGroupOracle()\n",
    "al = ActiveLearner(model, ngdataset, MinDiffSelector, oracle)\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "al.fit()\n",
    "scores.append(al.model.score(X_test, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    selected = al.select(10)\n",
    "    y = al.ask(selected)\n",
    "    al.tag_elements(selected, y)\n",
    "    al.fit()\n",
    "    scores.append(al.model.score(X_test, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.ylim(0,1)\n",
    "#plt.xlim(200,1000)\n",
    "plt.plot(al.get_scores())\n",
    "plt.plot(scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "al.change_selector(MinDiffSelector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis",
   "language": "python",
   "name": "tesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
